{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#33ccff\">Notebook for downloading and scoring tweets that match given hashtags</font>\n",
    "<img src=https://www.softwareadvice.com/resources/wp-content/uploads/The-Best-Free-Tools-for-Twitter-Sentiment-Analysis-Tile.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"consumer_key\"\n",
    "consumer_secret = \"consumer_secret\"\n",
    "access_token_key = \"access_token_key\"\n",
    "access_token_secret = \"asccess_token_secret\"\n",
    "\n",
    "credentials = dict(\n",
    "    consumer_key=consumer_key,\n",
    "    consumer_secret=consumer_secret,\n",
    "    access_token_key=access_token_key,\n",
    "    access_token_secret=access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save credentials to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# filename = \"credentials\"\n",
    "# with open(filename, \"wb\") as cred_fd:\n",
    "#     pickle.dump(credentials, cred_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials \n",
    "<font color='red'>NOTE:</font> that you don't want other people to know them, so do not commit and push accidently do github or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"credentials\", \"rb\") as cred_fd:\n",
    "    credentials = pickle.load(cred_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "\n",
    "class TwitterDownloader:\n",
    "    def __init__(self, credentials):\n",
    "        self.api = twitter.Api(**credentials, sleep_on_rate_limit=True)\n",
    "        self.data = []\n",
    "      \n",
    "    @staticmethod\n",
    "    def extract_tweet_data(tweet):\n",
    "        return {\n",
    "            \"created_at\" : tweet.created_at,\n",
    "            \"created_at_seconds\" : tweet.created_at_in_seconds,\n",
    "            \"id\" : tweet.id_str,\n",
    "            \"lang\" : tweet.lang,\n",
    "            \"user\" : tweet.user.name,\n",
    "            \"full_text\" : tweet.full_text\n",
    "        }\n",
    "    \n",
    "    def tweets_with_hashtags_generator(self, hashtags, lang, max_tweets=1000):\n",
    "        \"\"\"\n",
    "        Download tweets with given hashtags. Minimum is 100.\n",
    "        :param hashtags: list of lists, if you want tweets with multiple hashtags inside or string (or 1 elem list) if \n",
    "                         only one hashtag in tweet.\n",
    "        \"\"\"\n",
    "        downloaded_tweets = 0\n",
    "        previous_downloaded = -1\n",
    "        max_id = 0\n",
    "        \n",
    "        while downloaded_tweets < max_tweets:\n",
    "            if previous_downloaded == downloaded_tweets:\n",
    "                print(\"No more tweets to download, ending...\")\n",
    "                break\n",
    "                \n",
    "                \n",
    "            previous_downloaded = downloaded_tweets\n",
    "            for in_tweet_hashtags in hashtags:\n",
    "                \n",
    "                if isinstance(in_tweet_hashtags, str):\n",
    "                    hashtags_query = \"%23\" + in_tweet_hashtags\n",
    "                elif isinstance(in_tweet_hashtags, list) or isinstance(in_tweet_hashtags, tuple):\n",
    "                    hashtags_query = \"%23\" + in_tweet_hashtags[0] if len(in_tweet_hashtags) == 1 else \"%23\" + \"%23\".join(in_tweet_hashtags)\n",
    "                else:\n",
    "                    raise(\n",
    "                        TypeError(\n",
    "                            \"Elements of hashtags list have to be list or tuple - if multiple hashtags or string if 1 wanted\"\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                # This is next chunk of tweets so we want to download tweets older than the oldest already downloaded\n",
    "                # Initialized by 0\n",
    "                \n",
    "                # TODO: Test this \n",
    "                if max_id ==0:\n",
    "                    query = 'q={}&lang={}&tweet_mode=extended&count=100'.format(hashtags_query,lang)\n",
    "                else:\n",
    "                    query = 'q={}&lang={}&tweet_mode=extended&count=100&max_id={}'.format(hashtags_query,lang,max_id - 1)\n",
    "                \n",
    "                logging.info(\"Query: {}\".format(hashtags_query))\n",
    "                \n",
    "                tweets = api.GetSearch(\n",
    "                        raw_query=query\n",
    "                    )\n",
    "                if len(tweets) == 0:\n",
    "                    print(\"No more tweets for hashtag:\", in_tweet_hashtags, sep=\" \")\n",
    "                    break\n",
    "                    \n",
    "                for tweet in tweets:\n",
    "                    parsed_tweet = self.extract_tweet_data(tweet)\n",
    "                    self.data.append(parsed_tweet)\n",
    "                    if max_id ==0:\n",
    "                        max_id = parsed_tweet[\"id\"]\n",
    "                    else:\n",
    "                        max_id = min(max_id, parsed_tweet[\"id\"])\n",
    "                    yield parsed_tweet\n",
    "                    downloaded_tweets+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create downloader object with credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TwitterDownloader(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate hashtags to download tweets from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['android', 'apple'],\n",
       " ['android', 'iphone'],\n",
       " ['android', 'xiaomi'],\n",
       " ['android', 'htc'],\n",
       " ['ios', 'apple'],\n",
       " ['ios', 'iphone'],\n",
       " ['ios', 'xiaomi'],\n",
       " ['ios', 'htc'],\n",
       " ['smartfon', 'apple'],\n",
       " ['smartfon', 'iphone'],\n",
       " ['smartfon', 'xiaomi'],\n",
       " ['smartfon', 'htc'],\n",
       " ['telefon', 'apple'],\n",
       " ['telefon', 'iphone'],\n",
       " ['telefon', 'xiaomi'],\n",
       " ['telefon', 'htc']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "hashtags1 = [\"android\", \"ios\", \"smartfon\", \"telefon\"]\n",
    "hashtags2 = [\"apple\", \"iphone\", \"xiaomi\", \"htc\" or \"samsung\"]\n",
    "\n",
    "hashtags = [list(element) for element in itertools.product(hashtags1, hashtags2)]\n",
    "\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start downloading tweets, rate limits will be held automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_generator = td.tweets_with_hashtags_generator(hashtags=hashtags,lang=\"pl\", max_tweets=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-7d178ed73aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove tweets_file if you want to start from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets.csv'"
     ]
    }
   ],
   "source": [
    "# remove tweets_file if you want to start from scratch\n",
    "os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Query: %23android%23apple\n",
      "INFO:root:Query: %23android%23iphone\n",
      "INFO:root:Query: %23android%23xiaomi\n",
      "INFO:root:Query: %23android%23htc\n",
      "INFO:root:Query: %23ios%23apple\n",
      "INFO:root:Query: %23ios%23iphone\n",
      "INFO:root:Query: %23ios%23xiaomi\n",
      "INFO:root:Query: %23ios%23htc\n",
      "INFO:root:Query: %23smartfon%23apple\n",
      "INFO:root:Query: %23smartfon%23iphone\n",
      "INFO:root:Query: %23smartfon%23xiaomi\n",
      "INFO:root:Query: %23smartfon%23htc\n",
      "INFO:root:Query: %23telefon%23apple\n",
      "INFO:root:Query: %23telefon%23iphone\n",
      "INFO:root:Query: %23telefon%23xiaomi\n",
      "INFO:root:Query: %23telefon%23htc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more tweets to download, ending...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = \"tweets.csv\"\n",
    "\n",
    "if os.path.isfile(csv_file):\n",
    "    print(\"Loading from file:\", csv_file, sep=\" \")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.reindex()\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "for tweet in tweets_generator:\n",
    "    continue\n",
    "    tweet[\"score\"] = None\n",
    "    df = df.append(tweet, ignore_index=True)\n",
    "    df.to_csv(path_or_buf=csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"android\" or \"ios\" or \"smartfon\" or \"telefon\") and \\\n",
    "(\"apple\" or \"iphone\" or \"xiaomi\" or \"htc\" or \"samsung\") in [\"andriod\",\"iphone\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface for easy <font color=\"#33ccff\">tweets </font> scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most recent version of data\n",
    "df = pd.read_csv(csv_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i, tweet in df.iterrows():\n",
    "    score = tweet.score\n",
    "    if math.isnan(score) or score > 1.0 or score <-1.0:\n",
    "        score = 45444 # random, not between [-1,1]\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    while score > 1.0 or score <-1.0:\n",
    "        tmp_score = input(\"{}: {}\\n\".format(i, tweet.full_text))\n",
    "        try:\n",
    "            score = float(tmp_score)\n",
    "            if score <-1.0 or score > 1.0:\n",
    "                raise ValueError\n",
    "        except ValueError:\n",
    "            print(\"Score must be betweet -1.0 and 1.0\")\n",
    "    clear_output()\n",
    "    \n",
    "    df.loc[i, \"score\"] = score\n",
    "    \n",
    "    # save scored data\n",
    "    df.to_csv(path_or_buf=csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterSentimentAnalyser-NN",
   "language": "python",
   "name": "twittersentimentanalyser-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

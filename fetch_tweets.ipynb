{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#33ccff\">Notebook for downloading and scoring tweets that match given hashtags</font>\n",
    "<img src=https://www.softwareadvice.com/resources/wp-content/uploads/The-Best-Free-Tools-for-Twitter-Sentiment-Analysis-Tile.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"consumer_key\"\n",
    "consumer_secret = \"consumer_secret\"\n",
    "access_token_key = \"access_token_key\"\n",
    "access_token_secret = \"asccess_token_secret\"\n",
    "\n",
    "credentials = dict(\n",
    "    consumer_key=consumer_key,\n",
    "    consumer_secret=consumer_secret,\n",
    "    access_token_key=access_token_key,\n",
    "    access_token_secret=access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save credentials to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# filename = \"credentials\"\n",
    "# with open(filename, \"wb\") as cred_fd:\n",
    "#     pickle.dump(credentials, cred_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials \n",
    "<font color='red'>NOTE:</font> that you don't want other people to know them, so do not commit and push accidently do github or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"credentials\", \"rb\") as cred_fd:\n",
    "    credentials = pickle.load(cred_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "\n",
    "class TwitterDownloader:\n",
    "    def __init__(self, credentials):\n",
    "        self.api = twitter.Api(**credentials, sleep_on_rate_limit=True)\n",
    "        self.data = []\n",
    "      \n",
    "    @staticmethod\n",
    "    def extract_tweet_data(tweet):\n",
    "        return {\n",
    "            \"created_at\" : tweet.created_at,\n",
    "            \"created_at_seconds\" : tweet.created_at_in_seconds,\n",
    "            \"id\" : tweet.id_str,\n",
    "            \"lang\" : tweet.lang,\n",
    "            \"user\" : tweet.user.name,\n",
    "            \"full_text\" : tweet.full_text\n",
    "        }\n",
    "    \n",
    "    def tweets_with_hashtags_generator(self, hashtags, lang, max_tweets=1000):\n",
    "        \"\"\"\n",
    "        Download tweets with given hashtags. Minimum is 100.\n",
    "        :param hashtags: list of lists, if you want tweets with multiple hashtags inside or string (or 1 elem list) if \n",
    "                         only one hashtag in tweet.\n",
    "        \"\"\"\n",
    "        downloaded_tweets = 0\n",
    "        previous_downloaded = -1\n",
    "        max_id = 0\n",
    "        \n",
    "        while downloaded_tweets < max_tweets:\n",
    "            if previous_downloaded == downloaded_tweets:\n",
    "                print(\"No more tweets to download, ending...\")\n",
    "                break\n",
    "                \n",
    "                \n",
    "            previous_downloaded = downloaded_tweets\n",
    "            for in_tweet_hashtags in hashtags:\n",
    "                \n",
    "                if isinstance(in_tweet_hashtags, str):\n",
    "                    hashtags_query = \"%23\" + in_tweet_hashtags\n",
    "                elif isinstance(in_tweet_hashtags, list) or isinstance(in_tweet_hashtags, tuple):\n",
    "                    hashtags_query = \"%23\" + in_tweet_hashtags[0] if len(in_tweet_hashtags) == 1 else \"%23\" + \"%23\".join(in_tweet_hashtags)\n",
    "                else:\n",
    "                    raise(\n",
    "                        TypeError(\n",
    "                            \"Elements of hashtags list have to be list or tuple - if multiple hashtags or string if 1 wanted\"\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                # This is next chunk of tweets so we want to download tweets older than the oldest already downloaded\n",
    "                # Initialized by 0\n",
    "                \n",
    "                # TODO: Test this \n",
    "                if max_id ==0:\n",
    "                    query = 'q={}&lang={}&tweet_mode=extended&count=100'.format(hashtags_query,lang)\n",
    "                else:\n",
    "                    query = 'q={}&lang={}&tweet_mode=extended&count=100&max_id={}'.format(hashtags_query,lang,max_id - 1)\n",
    "                \n",
    "                logging.info(\"Query: {}\".format(hashtags_query))\n",
    "                \n",
    "                tweets = self.api.GetSearch(\n",
    "                        raw_query=query\n",
    "                    )\n",
    "                if len(tweets) == 0:\n",
    "                    print(\"No more tweets for hashtag:\", in_tweet_hashtags, sep=\" \")\n",
    "                    break\n",
    "                    \n",
    "                for tweet in tweets:\n",
    "                    parsed_tweet = self.extract_tweet_data(tweet)\n",
    "                    self.data.append(parsed_tweet)\n",
    "                    if max_id ==0:\n",
    "                        max_id = parsed_tweet[\"id\"]\n",
    "                    else:\n",
    "                        max_id = min(max_id, parsed_tweet[\"id\"])\n",
    "                    yield parsed_tweet\n",
    "                    downloaded_tweets+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create downloader object with credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TwitterDownloader(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate hashtags to download tweets from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['android', 'apple'],\n",
       " ['android', 'iphone'],\n",
       " ['android', 'xiaomi'],\n",
       " ['android', 'htc'],\n",
       " ['ios', 'apple'],\n",
       " ['ios', 'iphone'],\n",
       " ['ios', 'xiaomi'],\n",
       " ['ios', 'htc'],\n",
       " ['smartfon', 'apple'],\n",
       " ['smartfon', 'iphone'],\n",
       " ['smartfon', 'xiaomi'],\n",
       " ['smartfon', 'htc'],\n",
       " ['telefon', 'apple'],\n",
       " ['telefon', 'iphone'],\n",
       " ['telefon', 'xiaomi'],\n",
       " ['telefon', 'htc']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "hashtags1 = [\"android\", \"ios\", \"smartfon\", \"telefon\"]\n",
    "hashtags2 = [\"apple\", \"iphone\", \"xiaomi\", \"htc\" or \"samsung\"]\n",
    "\n",
    "hashtags = [list(element) for element in itertools.product(hashtags1, hashtags2)]\n",
    "\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start downloading tweets, rate limits will be held automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_generator = td.tweets_with_hashtags_generator(hashtags=hashtags,lang=\"pl\", max_tweets=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tweets.csv'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-7d178ed73aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# remove tweets_file if you want to start from scratch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tweets.csv'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# remove tweets_file if you want to start from scratch\n",
    "os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Query: %23android%23apple\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-382d269a4277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-432f3c97ee42>\u001b[0m in \u001b[0;36mtweets_with_hashtags_generator\u001b[0;34m(self, hashtags, lang, max_tweets)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'q={}&lang={}&tweet_mode=extended&count=100'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'q={}&lang={}&tweet_mode=extended&count=100&max_id={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Query: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtags_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = \"tweets.csv\"\n",
    "\n",
    "if os.path.isfile(csv_file):\n",
    "    print(\"Loading from file:\", csv_file, sep=\" \")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.reindex()\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "for tweet in tweets_generator:\n",
    "    continue\n",
    "    tweet[\"score\"] = None\n",
    "    df = df.append(tweet, ignore_index=True)\n",
    "    df.to_csv(path_or_buf=csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"android\" or \"ios\" or \"smartfon\" or \"telefon\") and \\\n",
    "(\"apple\" or \"iphone\" or \"xiaomi\" or \"htc\" or \"samsung\") in [\"andriod\",\"iphone\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface for easy <font color=\"#33ccff\">tweets </font> scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3fe93cf0cbf4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the most recent version of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Load the most recent version of data\n",
    "df = pd.read_csv(csv_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from IPython.display import clear_output\n",
    "\n",
    "for i, tweet in df.iterrows():\n",
    "    score = tweet.score\n",
    "    if math.isnan(score) or score > 1.0 or score <-1.0:\n",
    "        score = 45444 # random, not between [-1,1]\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    while score > 1.0 or score <-1.0:\n",
    "        tmp_score = input(\"{}: {}\\n\".format(i, tweet.full_text))\n",
    "        try:\n",
    "            score = float(tmp_score)\n",
    "            if score <-1.0 or score > 1.0:\n",
    "                raise ValueError\n",
    "        except ValueError:\n",
    "            print(\"Score must be betweet -1.0 and 1.0\")\n",
    "    clear_output()\n",
    "    \n",
    "    df.loc[i, \"score\"] = score\n",
    "    \n",
    "    # save scored data\n",
    "    df.to_csv(path_or_buf=csv_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterSentimentAnalyser-NN",
   "language": "python",
   "name": "twittersentimentanalyser-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

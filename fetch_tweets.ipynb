{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"#33ccff\">Notebook for downloading and scoring tweets that match given hashtags</font>\n",
    "<img src=https://www.softwareadvice.com/resources/wp-content/uploads/The-Best-Free-Tools-for-Twitter-Sentiment-Analysis-Tile.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"consumer_key\"\n",
    "consumer_secret = \"consumer_secret\"\n",
    "access_token_key = \"access_token_key\"\n",
    "access_token_secret = \"asccess_token_secret\"\n",
    "\n",
    "credentials = dict(\n",
    "    consumer_key=consumer_key,\n",
    "    consumer_secret=consumer_secret,\n",
    "    access_token_key=access_token_key,\n",
    "    access_token_secret=access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save credentials to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# filename = \"credentials\"\n",
    "# with open(filename, \"wb\") as cred_fd:\n",
    "#     pickle.dump(credentials, cred_fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load credentials \n",
    "<font color='red'>NOTE:</font> that you don't want other people to know them, so do not commit and push accidently do github or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"credentials\", \"rb\") as cred_fd:\n",
    "    credentials = pickle.load(cred_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "\n",
    "class TwitterDownloader:\n",
    "    def __init__(self, credentials):\n",
    "        self.api = twitter.Api(**credentials, sleep_on_rate_limit=True)\n",
    "        self.data = []\n",
    "      \n",
    "    @staticmethod\n",
    "    def extract_tweet_data(tweet):\n",
    "        return {\n",
    "            \"created_at\" : tweet.created_at,\n",
    "            \"created_at_seconds\" : tweet.created_at_in_seconds,\n",
    "            \"id\" : tweet.id_str,\n",
    "            \"lang\" : tweet.lang,\n",
    "            \"user\" : tweet.user.name,\n",
    "            \"full_text\" : tweet.full_text\n",
    "        }\n",
    "    \n",
    "    def tweets_with_hashtags_generator(self, hashtags, lang, max_tweets=1000):\n",
    "        \"\"\"\n",
    "        Download tweets with given hashtags. Minimum is 100.\n",
    "        :param hashtags: list of lists, if you want tweets with multiple hashtags inside or string (or 1 elem list) if \n",
    "                         only one hashtag in tweet.\n",
    "        \"\"\"\n",
    "        downloaded_tweets = 0\n",
    "        previous_downloaded = -1\n",
    "        max_id = 0\n",
    "        \n",
    "        while downloaded_tweets < max_tweets:\n",
    "            if previous_downloaded == downloaded_tweets:\n",
    "                print(\"No more tweets to download, ending...\")\n",
    "                break\n",
    "                \n",
    "                \n",
    "            previous_downloaded = downloaded_tweets\n",
    "            for in_tweet_hashtags in hashtags:\n",
    "                \n",
    "                if isinstance(in_tweet_hashtags, str):\n",
    "                    hashtags_query = \"%23\" + in_tweet_hashtags\n",
    "                elif isinstance(in_tweet_hashtags, list) or isinstance(in_tweet_hashtags, tuple):\n",
    "                    hashtags_query = \"%23\" + in_tweet_hashtags[0] if len(in_tweet_hashtags) == 1 else \"%23\" + \"%23\".join(in_tweet_hashtags)\n",
    "                else:\n",
    "                    raise(\n",
    "                        TypeError(\n",
    "                            \"Elements of hashtags list have to be list or tuple - if multiple hashtags or string if 1 wanted\"\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                # This is next chunk of tweets so we want to download tweets older than the oldest already downloaded\n",
    "                # Initialized by 0\n",
    "                \n",
    "                # TODO: Test this \n",
    "                if max_id ==0:\n",
    "                    query = 'q={}&lang={}&tweet_mode=extended&count=100'.format(hashtags_query,lang)\n",
    "                else:\n",
    "                    query = 'q={}&lang={}&tweet_mode=extended&count=100&max_id={}'.format(hashtags_query,lang,max_id - 1)\n",
    "                \n",
    "                logging.info(\"Query: {}\".format(hashtags_query))\n",
    "                \n",
    "                tweets = self.api.GetSearch(\n",
    "                        raw_query=query\n",
    "                    )\n",
    "                if len(tweets) == 0:\n",
    "                    print(\"No more tweets for hashtag:\", in_tweet_hashtags, sep=\" \")\n",
    "                    break\n",
    "                    \n",
    "                for tweet in tweets:\n",
    "                    parsed_tweet = self.extract_tweet_data(tweet)\n",
    "                    self.data.append(parsed_tweet)\n",
    "                    if max_id ==0:\n",
    "                        max_id = parsed_tweet[\"id\"]\n",
    "                    else:\n",
    "                        max_id = min(max_id, parsed_tweet[\"id\"])\n",
    "                    yield parsed_tweet\n",
    "                    downloaded_tweets+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create downloader object with credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TwitterDownloader(credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate hashtags to download tweets from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "hashtags1 = [\"android\", \"ios\", \"smartfon\", \"telefon\"]\n",
    "hashtags2 = [\"apple\", \"iphone\", \"xiaomi\", \"htc\" or \"samsung\"]\n",
    "\n",
    "hashtags = [list(element) for element in itertools.product(hashtags1, hashtags2)]\n",
    "\n",
    "hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start downloading tweets, rate limits will be held automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_generator = td.tweets_with_hashtags_generator(hashtags=hashtags,lang=\"pl\", max_tweets=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tweets_file if you want to start from scratch\n",
    "os.remove(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = \"tweets.csv\"\n",
    "\n",
    "if os.path.isfile(csv_file):\n",
    "    print(\"Loading from file:\", csv_file, sep=\" \")\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df.reindex()\n",
    "else:\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "for tweet in tweets_generator:\n",
    "    continue\n",
    "    tweet[\"score\"] = None\n",
    "    df = df.append(tweet, ignore_index=True)\n",
    "    df.to_csv(path_or_buf=csv_file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\"android\" or \"ios\" or \"smartfon\" or \"telefon\") and \\\n",
    "(\"apple\" or \"iphone\" or \"xiaomi\" or \"htc\" or \"samsung\") in [\"andriod\",\"iphone\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterSentimentAnalyser-NN",
   "language": "python",
   "name": "twittersentimentanalyser-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

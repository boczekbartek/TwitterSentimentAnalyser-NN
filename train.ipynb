{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from process import *\n",
    "from nn.MLP import MLPNetwork\n",
    "from coding import Coding\n",
    "from utils import get_train_data, simplify\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.utils import to_categorical\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and preprocess it by applying stemming and lemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from file: tweets_apple.csv\n"
     ]
    }
   ],
   "source": [
    "train_df = get_train_data()\n",
    "train_df['processed_tokens'] = train_df.full_text.apply(tokenize_and_remove_punkt).apply(stem).apply(lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "coder = Coding()\n",
    "_ = train_df.processed_tokens.apply(coder.update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set unified number of words to pad or truncate each twitt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_num_words = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set number of miminal occurrences of word in dict to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_occ = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dict based on aceding occurrences value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = coder.compile(min_threshold=min_occ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['coded_tokens'] = (\n",
    "    train_df\n",
    "    .processed_tokens\n",
    "    .apply(lambda l: [coder.encode_final(tok) for tok in l])\n",
    "    .apply(partial(pad_or_truncate, target_len=target_num_words, end=True, pad_value=0))\n",
    "    .apply(np.array)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get probe of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>score</th>\n",
       "      <th>processed_tokens</th>\n",
       "      <th>coded_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>RT @the_best_daily: 42% OFF #sale #save #apple...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[RT, the_best_daili, 42, off, sale, save, appl...</td>\n",
       "      <td>[199, 0, 0, 126, 72, 73, 205, 170, 0, 30, 164,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>When Tim Cook claimed using personal data wasn...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[when, tim, cook, claim, use, person, data, wa...</td>\n",
       "      <td>[0, 0, 0, 0, 89, 117, 187, 0, 204, 0, 194, 205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>#Facebook removes trending news, #Appleâ€™s upco...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[facebook, remov, trend, news, appl, s, upcom,...</td>\n",
       "      <td>[191, 0, 0, 49, 205, 196, 0, 182, 24, 196, 179...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>enjoy  #Apple spotlights young #developers ahe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[enjoy, appl, spotlight, young, develop, ahead...</td>\n",
       "      <td>[0, 205, 91, 92, 153, 141, 194, 195, 203, 204,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>RT @JanRomes: If Apple iBooks is how you read ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[RT, janrom, If, appl, ibook, be, how, you, re...</td>\n",
       "      <td>[199, 0, 0, 205, 0, 198, 84, 171, 32, 0, 0, 85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>5% OFF #sale #save #ipad #apple @amazon @apple...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[5, off, sale, save, ipad, appl, amazon, appl,...</td>\n",
       "      <td>[115, 126, 72, 73, 97, 205, 164, 205, 205, 97,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Time to set 15 alarms to ensure I wake up ðŸš¨ #W...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[time, to, set, 15, alarm, to, ensur, I, wake,...</td>\n",
       "      <td>[158, 201, 0, 0, 0, 201, 0, 189, 0, 29, 182, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>RT @BGRIndia: #WWDC2018: #Apple to introduce s...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[RT, bgrindia, wwdc2018, appl, to, introduc, s...</td>\n",
       "      <td>[199, 0, 175, 205, 201, 0, 145, 6, 0, 15, 0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>#WWDC2018: #Apple to introduce shared AR platf...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[wwdc2018, appl, to, introduc, share, AR, plat...</td>\n",
       "      <td>[175, 205, 201, 0, 145, 6, 0, 15, 0, 0, 113, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>RT @DannyCheng: Apple Shares Animoji Karaoke A...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[RT, dannycheng, appl, share, animoji, karaok,...</td>\n",
       "      <td>[199, 0, 205, 145, 0, 0, 0, 193, 174, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             full_text  score  \\\n",
       "233  RT @the_best_daily: 42% OFF #sale #save #apple...    3.0   \n",
       "95   When Tim Cook claimed using personal data wasn...    1.0   \n",
       "180  #Facebook removes trending news, #Appleâ€™s upco...    3.0   \n",
       "218  enjoy  #Apple spotlights young #developers ahe...    4.0   \n",
       "209  RT @JanRomes: If Apple iBooks is how you read ...    3.0   \n",
       "123  5% OFF #sale #save #ipad #apple @amazon @apple...    3.0   \n",
       "81   Time to set 15 alarms to ensure I wake up ðŸš¨ #W...    4.0   \n",
       "77   RT @BGRIndia: #WWDC2018: #Apple to introduce s...    3.0   \n",
       "98   #WWDC2018: #Apple to introduce shared AR platf...    3.0   \n",
       "239  RT @DannyCheng: Apple Shares Animoji Karaoke A...    3.0   \n",
       "\n",
       "                                      processed_tokens  \\\n",
       "233  [RT, the_best_daili, 42, off, sale, save, appl...   \n",
       "95   [when, tim, cook, claim, use, person, data, wa...   \n",
       "180  [facebook, remov, trend, news, appl, s, upcom,...   \n",
       "218  [enjoy, appl, spotlight, young, develop, ahead...   \n",
       "209  [RT, janrom, If, appl, ibook, be, how, you, re...   \n",
       "123  [5, off, sale, save, ipad, appl, amazon, appl,...   \n",
       "81   [time, to, set, 15, alarm, to, ensur, I, wake,...   \n",
       "77   [RT, bgrindia, wwdc2018, appl, to, introduc, s...   \n",
       "98   [wwdc2018, appl, to, introduc, share, AR, plat...   \n",
       "239  [RT, dannycheng, appl, share, animoji, karaok,...   \n",
       "\n",
       "                                          coded_tokens  \n",
       "233  [199, 0, 0, 126, 72, 73, 205, 170, 0, 30, 164,...  \n",
       "95   [0, 0, 0, 0, 89, 117, 187, 0, 204, 0, 194, 205...  \n",
       "180  [191, 0, 0, 49, 205, 196, 0, 182, 24, 196, 179...  \n",
       "218  [0, 205, 91, 92, 153, 141, 194, 195, 203, 204,...  \n",
       "209  [199, 0, 0, 205, 0, 198, 84, 171, 32, 0, 0, 85...  \n",
       "123  [115, 126, 72, 73, 97, 205, 164, 205, 205, 97,...  \n",
       "81   [158, 201, 0, 0, 0, 201, 0, 189, 0, 29, 182, 2...  \n",
       "77   [199, 0, 175, 205, 201, 0, 145, 6, 0, 15, 0, 0...  \n",
       "98   [175, 205, 201, 0, 145, 6, 0, 15, 0, 0, 113, 0...  \n",
       "239  [199, 0, 205, 145, 0, 0, 0, 193, 174, 0, 0, 0,...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define embeddings sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bartek/.virtualenvs/TwitterSentimentAnalyser-NN/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:45: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  if d.decorator_argspec is not None), _inspect.getargspec(target))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(coder.len_between(threshold_min=min_occ)+1, \n",
    "                    embedding_size, \n",
    "                    input_length=target_num_words))\n",
    "model.compile('rmsprop', 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_embeddings_arr = model.predict(np.array(train_df.coded_tokens.tolist()))\n",
    "embeddings = [i[0] for i in words_with_embeddings_arr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide if reduce number of classes from 5 to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reduce:\n",
    "    scores = [simplify(s) for s in train_df.score.tolist()]\n",
    "else:\n",
    "    scores = train_df.score.tolist()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply one-hot encoding on classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(embeddings)\n",
    "\n",
    "# one hot encoding\n",
    "y = to_categorical(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_percent = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=test_size_percent, \n",
    "                                                    # ensure same split every run\n",
    "                                                    random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in training_set: 213. Features: 64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of images in training_set: {}. Features: {}\"\n",
    "      .format(X_train.shape[0], X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes: {}\".format(y_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training parameters\n",
    "* num_features -> this will mean number of neurons in input layer as well as number of coded tokens in each input tweet passed to network\n",
    "* num_classes -> number of classes, number of neurons in output layer of network\n",
    "* num_hidden_neurons -> number of neurons in hidden layer\n",
    "* num_expamles -> number of examples in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "num_classes = y_train.shape[1]\n",
    "num_hidden_neurons = 1000\n",
    "num_examples = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MLPNetwork(n_classes=num_classes,n_features=num_features,\n",
    "                   n_hidden_units=num_hidden_neurons, epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [01:32<00:00, 108.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<nn.MLP.MLPNetwork at 0x12b2626a0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6171428571428571"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6052631578947368"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterSentimentAnalyser-NN",
   "language": "python",
   "name": "twittersentimentanalyser-nn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
